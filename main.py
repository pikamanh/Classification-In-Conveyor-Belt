import cv2
from queue import Queue
import threading
import torch
import time
import numpy as np

from ultralytics import YOLO
import supervision as sv
import serial.tools.list_ports

tracked_object = set()
object_timestamps = {}  # L∆∞u th·ªùi ƒëi·ªÉm v·∫≠t th·ªÉ ch·∫°m v√†o ƒë∆∞·ªùng ƒë·ªè
object_positions = {}

class VideoCaptureThread:
    def __init__(self, src):
        self.cap = cv2.VideoCapture(src, cv2.CAP_FFMPEG)
        self.cap.set(cv2.CAP_PROP_BUFFERSIZE, 2)
        self.q = Queue(maxsize=5)
        self.running = True
        self.thread = threading.Thread(target=self.update, daemon=True)
        self.thread.start()
    
    def update(self):
        while self.running:
            ret, frame = self.cap.read()
            if not ret:
                break
            if not self.q.full():
                self.q.put(frame)
    
    def read(self):
        return self.q.get() if not self.q.empty() else None
    
    def release(self):
        self.running = False
        self.thread.join()
        self.cap.release()

def get_arduino_port():
    ports = serial.tools.list_ports.comports()
    for port in ports:
        return port.device

def connect_arduino():
    arduino_port = get_arduino_port()
    if arduino_port is None:
        print("‚ùå Kh√¥ng t√¨m th·∫•y Arduino! Ki·ªÉm tra k·∫øt n·ªëi USB.")
        return None
    try:
        arduino = serial.Serial(arduino_port, 9600, timeout=1)
        time.sleep(2)
        print(f"‚úÖ K·∫øt n·ªëi Arduino th√†nh c√¥ng tr√™n {arduino_port}!")
        return arduino
    except Exception as e:
        print(f"‚ùå L·ªói k·∫øt n·ªëi Arduino ({arduino_port}): {e}")
        return None

def belt(frame, crop_x_start, crop_x_end, crop_y_start, crop_y_end, rb=False):
    #Belt
    belt_frame = frame[crop_y_start-20:crop_y_end+20, crop_x_start-30:crop_x_end+20]

    if rb == False:
        # √Åp d·ª•ng b·ªô l·ªçc tƒÉng c∆∞·ªùng s·∫Øc n√©t
        kernel_sharpening = np.array([[-1, -1, -1],
                                    [-1,  9, -1],
                                    [-1, -1, -1]])
        belt_frame = cv2.filter2D(belt_frame, -1, kernel_sharpening)

    return belt_frame

def count(frame, crop_x_start, crop_x_end, crop_y_start, crop_y_end):
    count_frame = frame[crop_y_start:crop_y_end, crop_x_start:crop_x_end]

    # L·∫•y k√≠ch th∆∞·ªõc m√†n h√¨nh (c√≥ th·ªÉ thay b·∫±ng k√≠ch th∆∞·ªõc mong mu·ªën)
    screen_width = 1080  # Thay b·∫±ng ƒë·ªô ph√¢n gi·∫£i m√†n h√¨nh th·ª±c t·∫ø
    screen_height = 720

    # Resize frame ƒë·ªÉ hi·ªÉn th·ªã to√†n m√†n h√¨nh
    count_frame_resized = cv2.resize(count_frame, (screen_width, screen_height), interpolation=cv2.INTER_LINEAR)

    return count_frame_resized  # Tr·∫£ v·ªÅ frame ƒë√£ resize n·∫øu c·∫ßn d√πng ti·∫øp

def count_box(frame, count_list, font, font_scale, thickness):
    #K√≠ch th∆∞·ªõc ch·ªØ
    (text_w_t, text_h_t), _ = cv2.getTextSize(f"Triangle: {count_list['triangle']}", font, font_scale, thickness)
    (text_w_r, text_h_r), _ = cv2.getTextSize(f"Rectangle: {count_list['rectangle']}", font, font_scale, thickness)

    #V·ªã tr√≠ ƒë·∫∑t ch·ªØ
    org_tri = (10, 60)
    org_rect = (frame.shape[1]-450, 60)

    #V·∫Ω n·ªÅn ƒëen
    cv2.rectangle(frame, (org_tri[0] - 5, org_tri[1] - text_h_t - 5),
                    (org_tri[0] + text_w_t + 5, org_tri[1] + 20), (0, 0, 0), -1)
    cv2.rectangle(frame, (org_rect[0] - 5, org_rect[1] - text_h_r - 5),
                    (org_rect[0] + text_w_r + 5, org_rect[1] + 20), (0, 0, 0), -1)

    cv2.putText(img=frame,
                text=f"Triangle: {count_list['triangle']}",
                org=org_tri,
                fontFace=font,
                fontScale=font_scale,
                color=(0, 255, 0), 
                thickness=thickness)
    cv2.putText(img=frame,
                text=f"Rectangle: {count_list['rectangle']}",
                org=org_rect,
                fontFace=font,
                fontScale=font_scale,
                color=(0, 255, 0),
                thickness=thickness)

def show_frame(count_frame, combined_frame):
    list_frame_resized = []
    h = max(frame.shape[0] for frame in combined_frame)
    w = max(frame.shape[1] for frame in combined_frame)

    for frame in combined_frame:
        if len(frame.shape) == 2:
            list_frame_resized.append(cv2.cvtColor(cv2.resize(frame, (w, h)), cv2.COLOR_GRAY2BGR))
        else:
            list_frame_resized.append(cv2.resize(frame, (w, h)))
    
    combined_frame = np.hstack(list_frame_resized)

    cv2.imshow("Count", count_frame)
    cv2.imshow("Total", combined_frame)

def mouseMove(event, x, y):
    if event == cv2.EVENT_LBUTTONDOWN:
        print(f"({x}, {y})")

def main():
    global tracked_object, object_timestamps
    font, font_scale, thickness = cv2.FONT_HERSHEY_TRIPLEX, 2, 1

    count_list = {
        'rectangle': 0,
        'triangle': 0
    }

    cap = VideoCaptureThread("rtsp://username:password@ip_address:554/stream1")
    # cap = cv2.VideoCapture(0)

    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"‚ö° Running on: {device.upper()}")

    model = YOLO(r"model\best new v2.pt").to(device)
    arduino = connect_arduino()

    bounding_box_annotator = sv.BoxAnnotator()
    label_annotator = sv.LabelAnnotator()
    tracker = sv.ByteTrack(track_activation_threshold=0.3, minimum_matching_threshold=0.8, lost_track_buffer=90)

    while True:
        frame = cap.read()

        if frame is None:
            continue

        # Define Frame
        crop_x_start_detect, crop_x_end_detect = 530, 780
        crop_y_start_detect, crop_y_end_detect = 500, 850

        #Belt Frame
        belt_frame = belt(frame.copy(), crop_x_start_detect, crop_x_end_detect, crop_y_start_detect, crop_y_end_detect, rb=True)

        # Count
        crop_x_start_count, crop_x_end_count = crop_x_start_detect - 150, crop_x_end_detect + 150
        crop_y_start_count, crop_y_end_count = crop_y_start_detect - 100, crop_y_end_detect
        count_frame = count(frame, crop_x_start_count, crop_x_end_count, crop_y_start_count, crop_y_end_count)

        # cv2.namedWindow('Frame')
        # cv2.setMouseCallback('Frame', mouseMove)
        # cv2.imshow("Frame", frame)

        # cv2.namedWindow('Count')
        # cv2.setMouseCallback('Count', mouseMove)

        result = model(belt_frame, verbose=False)[0]
        detections = sv.Detections.from_ultralytics(result)
        detections = tracker.update_with_detections(detections)

        labels = [
            f"{tracker_id}: {class_name} {confidence:.2f}"
            for tracker_id, class_name, confidence in zip(
                list(detections.tracker_id) if detections.tracker_id is not None else [],
                list(detections['class_name']) if detections["class_name"] is not None else [],
                list(detections.confidence) if detections.confidence is not None else []
            )
        ]

        # T√≠nh v·ªã tr√≠ d√≤ng ƒë·ªè (·ªü gi·ªØa belt)
        line_y = 60
        cv2.line(belt_frame, (0, line_y), (count_frame.shape[1], line_y), (0, 0, 255), 2)  # ƒê∆∞·ªùng m√†u ƒë·ªè

        for obj_id, class_id, confidence, (x, y, _, _) in zip(detections.tracker_id, detections.class_id, detections.confidence, detections.xyxy):
            if confidence >= 0.8: #0.7
                if y <= line_y and obj_id not in tracked_object:
                    print(f"üîπ V·∫≠t th·ªÉ {obj_id}: {class_id} {confidence} ch·∫°m v√†o ƒë∆∞·ªùng!")

                    if obj_id not in object_timestamps:
                        object_timestamps[obj_id] = time.time()  # L∆∞u th·ªùi gian b·∫Øt ƒë·∫ßu d·ª´ng

                if obj_id in object_timestamps or obj_id in object_positions:
                    elapsed_time = time.time() - object_timestamps[obj_id]
                    if elapsed_time >= 5.5: # Th·ªùi gian t·ª´ l√∫c nh·∫≠n ƒë·∫øn l√∫c g·ª≠i t√≠n hi·ªáu ƒë·∫øn Arduino l√† 6.5s
                        print("ƒê√£ g·ª≠i t√≠n hi·ªáu.")
                        if arduino is not None:
                            if class_id == 0:
                                arduino.write(b'1')
                                count_list['rectangle'] += 1
                            else:
                                arduino.write(b'2')
                                count_list['triangle'] += 1 
                            print(f"üõ†Ô∏è G·ª≠i t√≠n hi·ªáu ƒë·∫øn Arduino cho v·∫≠t th·ªÉ {obj_id}")

                        tracked_object.add(obj_id)
                        del object_timestamps[obj_id]  # X√≥a kh·ªèi danh s√°ch ch·ªù

            annotated_image = bounding_box_annotator.annotate(scene=belt_frame, detections=detections)
            annotated_image = label_annotator.annotate(scene=annotated_image, detections=detections, labels=labels)

        count_box(count_frame, count_list, font, font_scale, thickness)
        show_frame(count_frame, [belt_frame])

        if cv2.waitKey(1) == ord('q'):
            break

    cap.release()
    cv2.destroyAllWindows()
    if arduino:
        arduino.close()

if __name__ == '__main__':
    main()